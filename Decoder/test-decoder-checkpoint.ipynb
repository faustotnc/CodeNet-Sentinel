{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbhbgCwFAwbE",
        "outputId": "ebea8ade-65ca-4a5f-b331-149018564166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/codenet-sentinel/decoder\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.10.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Replace with correct location\n",
        "    %cd /content/drive/MyDrive/Colab Notebooks/codenet-sentinel/decoder\n",
        "\n",
        "    !pip install datasets transformers lightning wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# To make our imports work because python relative imports suck\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)"
      ],
      "metadata": {
        "id": "-tip9o8PA1dl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Local Modules\n",
        "from Architecture import  Tokenizer\n",
        "from Architecture.Decoder import DecoderModel"
      ],
      "metadata": {
        "id": "VeDjyyHyA8SE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VPIEG1T4A_3M",
        "outputId": "d18d12b7-b328-45fc-c786-ec3255b0c2d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_model = DecoderModel.load_from_checkpoint(\"./CodeNet-Sentinel-v1-decoder/560v2doi/checkpoints/epoch=2-step=9402.ckpt\")\n",
        "decoder_model = decoder_model.eval()"
      ],
      "metadata": {
        "id": "WzXvQx-jBMlC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Generation Test\n",
        "This file shows an example of loading the trained decoder model and generating text based on some inputs. For this particular example, we give the model the basic starting signature of a function in various programming languages, including the respective function keyword and the name of the function.\n",
        "\n",
        "\n",
        "Note that this model is not meant to generate coherent code (which it would probably never be able to, given the its size and resource limiations). Rather, the focus is on training the model to follow the basic syntax of various programming languages.\n",
        "\n",
        "\n",
        "Also note that this particular example provides a very small initial context to the model. Inputing a longer seed sequence could produce better resutls, as it would give the model a better idea of what to generate.\n",
        "\n",
        "Given these limitations, the model may not generate code that matches the programming language specified in the title the section. This is okay and expected."
      ],
      "metadata": {
        "id": "Xm-m6qxuENQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn_name = \"findLongestPath\""
      ],
      "metadata": {
        "id": "__4II4-8Cb7s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Javascript/Typescript"
      ],
      "metadata": {
        "id": "KzGzYY0mCexe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]function {fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbVpybkmBkgA",
        "outputId": "40763831-9f97-4c90-bea0-5fcaf7841b2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]function findLongestPath(origin: string, destination: string): number {\n",
            "  // dry run \"run\" to get weather information\n",
            "  if (!CheckDryRun()) {\n",
            "    return 'No weather data found';\n",
            "  }\n",
            "\n",
            "  let currentDriversation =\n",
            "    `The weather Data has been reported. We will not be enough to make any required).`;\n",
            "\n",
            "  // determine appropriate values based on trust level\n",
            "  if (trustLevel === 'low') {\n",
            "    return 5;\n",
            "  } else if (trustLevel ==='medium') {\n",
            "    return 9;\n",
            "  } else {\n",
            "    return 12;\n",
            "  }\n",
            "  \n",
            "  return 1;\n",
            "}\n",
            "\n",
            "// dry run check\n",
            "if (currentHeatServerTemp > 'high') {\n",
            "  console.log('There was any significant activity, needs improvement.')\n",
            "} else {\n",
            "  console.log('It appears like you already strong winds.')\n",
            "}[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python/Ruby"
      ],
      "metadata": {
        "id": "0kaQARrOCrRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]def {fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGN1x4paCNes",
        "outputId": "4d892111-2dd0-40cb-b2d6-67448c2a3d54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]def findLongestPath(condition)\n",
            "  # Check current day of readings \n",
            "  case condition\n",
            "    when :bad\n",
            "\n",
            "      puts \"LowestPath Detected\"\n",
            "      puts \"HighestPath Detected\" \n",
            "      puts \"-- return highestPathality.\" \n",
            "\n",
            "    when :high\n",
            "\n",
            "      puts \"HighestPath Right Detected\"\n",
            "    \n",
            "  end \n",
            "\n",
            "  return {\n",
            "    echo \"Common Enords detected. Current sunny count: $? \" + \n",
            "         \"'n' (Enter 'fully' to exit): \"]- \n",
            "\n",
            "    Trim\n",
            "      (@no]-> \"\\nHighestPath Selected!\\n\" \n",
            "    end \n",
            "\n",
            "  return CARE_COLEAR * (lowestPath.empty output) \n",
            "  end\n",
            "end[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C/C++/C#/Java"
      ],
      "metadata": {
        "id": "yqBLOHaPCuKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]int[] {fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ZstAU7CvZT",
        "outputId": "1467fa57-8839-4f9c-910d-cd28ab4618da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]int[] findLongestPath(vector<string>& distances) => {\"Passport Distance\", \"Time usage\"});\n",
            "\n",
            "    // Sort slice by highest%. alphabetically\n",
            "    sortsmallOrder(distances);\n",
            "    \n",
            "    // Get first element for current maximum value\n",
            "    double maxDistance = distances[0];\n",
            "    \n",
            "    // Compare distances based on current element status\n",
            "    if(maxDistance == Covered) \n",
            "        throw stdin(\"Max Draw: Never\" + maxDistance);\n",
            "    else if(maxDistance == Covered)\n",
            "        filteredString =Distance;\n",
            "        \n",
            "     // Check other than previous closest value of given distances\n",
            "    else if(maxDistance == Covered)\n",
            "        filteredString = filteredString && break ;\n",
            "    else    \n",
            "        filteredString = return -1;   \n",
            "    \n",
            "    return filteredString;\n",
            "}[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rust"
      ],
      "metadata": {
        "id": "Iys6tSLoDFpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]fn {fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAJlB973DGKe",
        "outputId": "dac96b53-6b4c-488b-d5ca-0d7e4bb41a6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]fn findLongestPath(odor_score: i32, water_source: &str) -> String {\n",
            "    let mut message = \"High\".to_string();\n",
            "\n",
            "    match odor_source {\n",
            "        x if x >= 0.8 => {\n",
            "            message += \"\\nThe most recent dizziness is considered good.\\n\";\n",
            "        }\n",
            "\n",
            "        1 => { return message;\n",
            "        }\n",
            "        // Return final message\n",
            "        message\n",
            "    }\n",
            "    \n",
            "    return message;\n",
            "}\n",
            "\n",
            "// Example usage\n",
            "let odor_source_level = {\n",
            "    Alcohol_source_level: 1, \n",
            "    plays_instructions: vec![\n",
            "    Event    Choose_instructions: Vec<(into_instructions, \n",
            "   Invested_source_level: 2.3, \n",
            "    Mall_shaped_level: 2.0, \n",
            "    alternative_source_level: 3.3 \n",
            "   years: 3.2, \n",
            "    ethical_source_level: 5.3, \n",
            "    alternate_source_level: 3.3 \n",
            "\n",
            "    wipes_company_level: 4.5, \n",
            "    source_level: 4. 7, \n",
            "    source_level: 5.4 // Estimated average effectiveness\n",
            "    eff_source_level: 1.7, \n",
            "   family_source_level: 4.2, \n",
            "    website_source_level: 3.2\n",
            "    Exam_source_level: 4.1 \n",
            "%)\n",
            "result if cough_source_level == 1.5...\n",
            "    if Ethical_source_level == 1.5\n",
            "        print!(\"There may be room for improvement.\", \n",
            "         usage_level)\n",
            "    else if ethical_source_level == 0.4\n",
            "        print!(\"It may be best to demonstrate safe.\")\n",
            "    else    \n",
            "        print!(\"The strong dryness\", \n",
            "           recommendation_source_level)\n",
            "    }\n",
            "    \n",
            "    println!(\"The combination of stains is considered good.\");\n",
            "    \n",
            "}[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Go"
      ],
      "metadata": {
        "id": "FE0KEdSqDYft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]func {fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSwp0AZ-DYF3",
        "outputId": "a8bda868-212f-4b9a-fbd0-6036d4f5ce44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]func findLongestPath(recordstring,symbol string) (string, error) {\n",
            "    // Create a client for a new workout session\n",
            "    session := driver.Clquery(\"latest\")\n",
            "\n",
            "    // Get the average step count from the retrieved record\n",
            "    avgStep := sum / len(record))\n",
            "\n",
            "    // Calculate the average step count by timestamp\n",
            "    avgStep := sum(record)\n",
            "\n",
            "    // Perform the average step count based on their average step count\n",
            "    var sum int\n",
            "    for scanner, row := range avgStep {\n",
            "        avgStep := record._epr(\"averageSteps\")\n",
            "\n",
            "        // Check if there are any abnormalities present and return\n",
            "        if avgStep > avgStep {\n",
            "            return false\n",
            "        },\n",
            "    }\n",
            "\n",
            "    // Calculate the average step count from this record\n",
            "    avgStepCount := sum(rec, avgStep) / len(3)\n",
            "\n",
            "    fmt.Println(\"Average steps count:\", avgStepCount)\n",
            "    fmt.Printf(\"Average steps count:\", avgStepCount)\n",
            "}[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Julia"
      ],
      "metadata": {
        "id": "xDuyoQTCEK_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = Tokenizer.encode(\n",
        "    f\"[BOS]{fn_name}(\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = decoder_model._generate(seed, max_new_tokens=2048)\n",
        "\n",
        "print(Tokenizer.decode(generated[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAHdWKdfDrEO",
        "outputId": "4fbd45ef-1b84-478a-86f8-3b359989df82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOS]findLongestPath(modeValue, minimumTransparency);\n",
            "\n",
            "if (modeValue < 1) {\n",
            "    // Safe41 - nose require flossing \n",
            "    return \"Engineer's\"; \n",
            "} else if (modeValue > 0 && modeValue <= 15) {\n",
            "    // Very efficient - treatment could go\n",
            "    return \"Lead demonstrates flossing through anyair diseases over very ha spikesfulloplasty, there are several factors affecting their teeth AND cleanliness Indicates severity.\"; \n",
            "} else {\n",
            "    // All LINE requires more on switch case \n",
            "    return \"Leched sides of teeth through daily but still classified verification required for maintaining good dental hygiene and cleanliness.\"; \n",
            "}[EOS]\n"
          ]
        }
      ]
    }
  ]
}